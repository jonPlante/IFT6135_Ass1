{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lBcUVChYluA"
   },
   "source": [
    " **Problem 3**\n",
    "\n",
    "\n",
    "https://colab.research.google.com/drive/1aSECHvD_jfC-6ErJMXUFT6RMJFiYyUfJ\n",
    "\n",
    "\n",
    "You must use the data generation script: https://github.com/jonPlante/IFT6135_Ass1/blob/master/generateData.py\n",
    "to prepare the data\n",
    "\n",
    "Then save on your drive as catDog.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "colab_type": "code",
    "id": "rI8i0EEqAgAD",
    "outputId": "589a968e-b492-447e-8024-858a7729ab79"
   },
   "outputs": [],
   "source": [
    "!pip3 install 'torch==0.4.0'\n",
    "!pip3 install 'torchvision==0.2.1'\n",
    "!pip3 install --no-cache-dir -I 'pillow==5.1.0'\n",
    "\n",
    "# Restart Kernel\n",
    "# This workaround is needed to properly upgrade PIL on Google Colab.\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "1DrCZu75L66j",
    "outputId": "eae3eeaf-c562-43c7-d92d-c8e91c5a7a0a"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/aleju/imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "YCGQ99w5GfHP",
    "outputId": "608785e6-4829-45cb-ef03-e38b9bc3b10b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RI4DjGX9Zlr"
   },
   "outputs": [],
   "source": [
    "with gzip.open('/content/gdrive/My Drive/catDog.pkl.gz', 'rb') as f:\n",
    "  train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRomArJbEgRy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cO6h5LZKAsYg"
   },
   "outputs": [],
   "source": [
    "torch_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.RandomGrayscale(),\n",
    "    torchvision.transforms.RandomAffine(20, translate=[0.1,0.1], scale=None, shear=5, resample=False, fillcolor=0),\n",
    "    torchvision.transforms.RandomResizedCrop(64, scale=(0.96, 1.0), ratio=(0.95, 1.05)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lJARzBWMVuI"
   },
   "outputs": [],
   "source": [
    "class ImgAugTransform:\n",
    "  def __init__(self):\n",
    "    self.aug = iaa.Sequential([\n",
    "        iaa.Scale((64, 64)),\n",
    "        iaa.Sometimes(0.6, iaa.GaussianBlur(sigma=(0, 2.0))),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
    "        iaa.Sometimes(0.6,\n",
    "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                 iaa.CoarseDropout(0.1, size_percent=0.7)])),\n",
    "        iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "    ])\n",
    "      \n",
    "  def __call__(self, img):\n",
    "    img = np.array(img)\n",
    "    return self.aug.augment_image(img)\n",
    "\n",
    "Img_Aug_T = ImgAugTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "id": "sH5Q6vE0Em4E",
    "outputId": "a8adb0f7-75ad-4b4b-d4b5-cf2270e161fa"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_set)\n",
    "train=[]\n",
    "valid=[]\n",
    "test=[]\n",
    "for i in range(len(train_set)):\n",
    "  x=torch.Tensor(train_set[i][0])\n",
    "  train.append([x,train_set[i][1]])\n",
    "  #data augmentation\n",
    "  for j in range(5):\n",
    "    #pytorch\n",
    "    x=torch_transform(Image.fromarray(np.uint8(np.moveaxis(train_set[i][0],0,2)*255)))\n",
    "    train.append([x,train_set[i][1]])\n",
    "    #dataAugment\n",
    "    x=Img_Aug_T(np.uint8(np.moveaxis(train_set[i][0],0,2)*255))\n",
    "    x=torch.Tensor(np.moveaxis(x/255,2,0))\n",
    "    train.append([x,train_set[i][1]])\n",
    "  train_set[i]=[]\n",
    "  if i%500==0 and not i==0:\n",
    "    print('\\t'+str(np.round(i/len(train_set)*100,2))+'% complete')\n",
    "train_set=[]\n",
    "for i in range(len(valid_set)):\n",
    "  x=torch.Tensor(valid_set[i][0])\n",
    "  valid.append([x,valid_set[i][1]])\n",
    "  valid_set[i]=[]\n",
    "valid_set=[]\n",
    "for i in range(len(test_set)):\n",
    "  x=torch.Tensor(test_set[i][0])\n",
    "  test.append([x,test_set[i][1]])\n",
    "  test_set[i]=[]\n",
    "test_set=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1uUl29KGUez"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1) \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3,padding=1,stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 1,padding=0,stride=2)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, 3,padding=1,stride=2)\n",
    "        self.conv8 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(128, 256, 1,padding=0,stride=2)\n",
    "        self.conv10 = nn.Conv2d(256, 512, 3,padding=1,stride=2)\n",
    "        self.conv11 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "        self.conv12 = nn.Conv2d(256, 512, 1,padding=0,stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512*1*1,1000)\n",
    "        self.fc2 = nn.Linear(1000, 2)\n",
    "        self.AvgPool = nn.AvgPool2d(8,1)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        residual_1=x\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x)+residual_1)\n",
    "        residual_2=x\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x)+residual_2)\n",
    "        residual_3=x\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv2(x)+residual_3)\n",
    "        residual_4=x\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x)+self.conv5(residual_4))\n",
    "        residual_5=x\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv6(x)+residual_5)\n",
    "        residual_6=x\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv6(x)+residual_6)\n",
    "        residual_7=x\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv6(x)+residual_7)\n",
    "        residual_8=x\n",
    "        \n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x)+self.conv9(residual_8))\n",
    "        residual_9=x\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv8(x)+residual_9)\n",
    "        residual_10=x\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv8(x)+residual_10)\n",
    "        residual_11=x\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv8(x)+residual_11)\n",
    "        residual_12=x\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv8(x)+residual_12)\n",
    "        residual_13=x\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv8(x)+residual_13)\n",
    "        residual_14=x\n",
    "        \n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = F.relu(self.conv11(x)+self.conv12(residual_14))\n",
    "        residual_15=x\n",
    "        \n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv11(x)+residual_15)\n",
    "        residual_16=x\n",
    "        \n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv11(x)+residual_16)\n",
    "        x=self.AvgPool(x)\n",
    "\n",
    "        x = x.view(-1, 512*1*1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "                \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3866
    },
    "colab_type": "code",
    "id": "7YTzzffSLKhu",
    "outputId": "a6b73dcb-3585-4a2f-f561-28f982588f0a"
   },
   "outputs": [],
   "source": [
    "epochs=60\n",
    "start=31\n",
    "MB=50\n",
    "LR=0.001\n",
    "use_cuda = True\n",
    "\n",
    "numTrain=len(train)\n",
    "numValid=len(valid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "#if want to load modelcomment\n",
    "#net.load_state_dict(torch.load('/content/gdrive/My Drive/model_'+str(start)+'.pkl'))\n",
    "\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    print('using cuda')\n",
    "else:\n",
    "  print('not using cuda')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=MB,shuffle=False, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size=MB,shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#nn.BCELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.0)\n",
    "\n",
    "train_data=np.zeros((epochs+1,3))\n",
    "valid_data=np.zeros((epochs+1,3))\n",
    "\n",
    "print('Calculating initial training loss')\n",
    "total_loss = 0.0\n",
    "total_error=0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    " # get the inputs\n",
    "  images, labels = data\n",
    "  images=Variable(images)\n",
    "  labels=Variable(labels)#.type(torch.FloatTensor))\n",
    " \n",
    "  if use_cuda and torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    " \n",
    "  outputs = net(images)\n",
    "  loss = criterion(outputs, labels)\n",
    "  total_error+=np.sum(np.abs(np.argmax(outputs.data.cpu().numpy(),axis=1)-labels.cpu().numpy()))\n",
    " \n",
    "  total_loss+=loss.data.cpu()\n",
    "  if i*MB%10000==0 and not i==0:\n",
    "    print('\\t'+str(np.round(i*MB/numTrain*100,2))+'% complete')\n",
    "\n",
    "   \n",
    "train_data[0,:]=[0,total_loss/(numTrain/MB),total_error/numTrain]\n",
    "print('Initial training loss: ' +str(np.round(train_data[0,1],2))+', training error: '+str(np.round(train_data[0,2]*100,2))+'%, training accuracy:'+str(np.round((1-train_data[0,2])*100,2))+'%')\n",
    "\n",
    "\n",
    "print('Calculating initial validation loss')\n",
    "total_loss = 0.0\n",
    "total_error=0\n",
    "for i, data in enumerate(validloader, 0):\n",
    "  # get the inputs\n",
    "  images, labels = data\n",
    "  images=Variable(images)\n",
    "  labels=Variable(labels)#.type(torch.FloatTensor))\n",
    "  \n",
    "  if use_cuda and torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "  \n",
    "  outputs = net(images)\n",
    "  loss = criterion(outputs, labels)\n",
    "  total_error+=np.sum(np.abs(np.argmax(outputs.data.cpu().numpy(),axis=1)-labels.cpu().numpy()))\n",
    "  total_loss+=loss.data.cpu()\n",
    "    \n",
    "valid_data[0,:]=[0,total_loss/(numValid/MB),total_error/numValid]\n",
    "print('Initial validation loss: ' +str(np.round(valid_data[0,1],2))+', validation error: '+str(np.round(valid_data[0,2]*100,2))+'%, validation accuracy:'+str(np.round((1-valid_data[0,2])*100,2))+'%')\n",
    "\n",
    "\n",
    "for epoch in range(start,epochs):  # loop over the dataset multiple times\n",
    "  \n",
    "  trainloader=[]\n",
    "  validloader=[]\n",
    "  train=[]\n",
    "  valid=[]\n",
    "  test=[]\n",
    "  \n",
    "  with gzip.open('/content/gdrive/My Drive/catDog.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "  \n",
    "  random.shuffle(train_set)\n",
    "  \n",
    "  for i in range(len(train_set)):\n",
    "    x=torch.Tensor(train_set[i][0])\n",
    "    train.append([x,train_set[i][1]])\n",
    "     #data augmentation\n",
    "    for j in range(3):\n",
    "      x=torch_transform(Image.fromarray(np.uint8(np.moveaxis(train_set[i][0],0,2)*255)))\n",
    "      train.append([x,train_set[i][1]])\n",
    "      x=Img_Aug_T(np.uint8(np.moveaxis(train_set[i][0],0,2)*255))\n",
    "      x=torch.Tensor(np.moveaxis(x/255,2,0))\n",
    "      train.append([x,train_set[i][1]])\n",
    "    train_set[i]=[]\n",
    "    if i%500==0 and not i==0:\n",
    "      print('\\t'+str(np.round(i/len(train_set)*100,2))+'% complete')\n",
    "  train_set=[]\n",
    "  for i in range(len(valid_set)):\n",
    "    x=torch.Tensor(valid_set[i][0])\n",
    "    valid.append([x,valid_set[i][1]])\n",
    "    valid_set[i]=[]\n",
    "  valid_set=[]\n",
    "  for i in range(len(test_set)):\n",
    "    x=torch.Tensor(test_set[i][0])\n",
    "    test.append([x,test_set[i][1]])\n",
    "    test_set[i]=[]\n",
    "  test_set=[]\n",
    "\n",
    "  trainloader = torch.utils.data.DataLoader(train, batch_size=MB,shuffle=False, num_workers=2)\n",
    "  validloader = torch.utils.data.DataLoader(valid, batch_size=MB,shuffle=False, num_workers=2)\n",
    "  \n",
    "  running_loss = 0.0\n",
    "  num_ex=0\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs\n",
    "    images, labels = data\n",
    "    images=Variable(images)\n",
    "    labels=Variable(labels)#.type(torch.FloatTensor))\n",
    "  \n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "        \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward + backward + optimize\n",
    "    outputs = net(images)\n",
    "    #print(outputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.data.cpu().numpy()\n",
    "    num_ex+=1\n",
    "    if i*MB%10000 == 0 and not i==0:\n",
    "      print('\\tLoss: '+str(np.round(running_loss/num_ex,3))+', '+str(np.round(i*MB/numTrain*100,2))+'% of epoch ' + str(epoch+1) +' complete')\n",
    "      num_ex=0\n",
    "      running_loss=0\n",
    "  print('Epoch '+str(epoch+1) + ' complete')\n",
    "  \n",
    "  torch.save(net.state_dict(), '/content/gdrive/My Drive/model_'+str(epoch+1)+'.pkl')\n",
    "                    \n",
    "  print('Calculating training loss')\n",
    "  total_loss = 0.0\n",
    "  total_error=0\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs\n",
    "    images, labels = data\n",
    "    images=Variable(images)\n",
    "    labels=Variable(labels)#.type(torch.FloatTensor))\n",
    "    \n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "  \n",
    "    outputs = net(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_error+=np.sum(np.abs(np.argmax(outputs.data.cpu().numpy(),axis=1)-labels.cpu().numpy()))\n",
    "    total_loss+=loss.data.cpu()\n",
    "    if i*MB%10000==0 and not i==0:\n",
    "      print('\\t'+str(np.round(i*MB/numTrain*100,2))+'% complete')\n",
    "    \n",
    "  train_data[epoch+1,:]=[epoch+1,total_loss/(numTrain/MB),total_error/numTrain]\n",
    "  print('Training loss: ' +str(np.round(train_data[epoch+1,1],2))+', training error: '+str(np.round(train_data[epoch+1,2]*100,2))+'%, training accuracy:'+str(np.round((1-train_data[epoch+1,2])*100,2))+'%')\n",
    "\n",
    "  print('Calculating validation loss')\n",
    "  total_loss = 0.0\n",
    "  total_error=0\n",
    "  for i, data in enumerate(validloader, 0):\n",
    "    # get the inputs\n",
    "    images, labels = data\n",
    "    images=Variable(images)\n",
    "    labels=Variable(labels)#.type(torch.FloatTensor))\n",
    "  \n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "  \n",
    "    outputs = net(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_error+=np.sum(np.abs(np.argmax(outputs.data.cpu().numpy(),axis=1)-labels.cpu().numpy()))\n",
    "    total_loss+=loss.data.cpu()\n",
    "    \n",
    "  valid_data[epoch+1,:]=[epoch+1,total_loss/(numValid/MB),total_error/numValid]\n",
    "  print('Validation loss: ' +str(np.round(valid_data[epoch+1,1],2))+', validation error: '+str(np.round(valid_data[epoch+1,2]*100,2))+'%, validation accuracy:'+str(np.round((1-valid_data[epoch+1,2])*100,2))+'%')\n",
    "         \n",
    "print('Finished Training')\n",
    "torch.cuda.empty_cache()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "tWKWfq--IUsE",
    "outputId": "c501bb7e-2e43-4f40-849b-4036a95198ae"
   },
   "outputs": [],
   "source": [
    "# if want to load model uncomment\n",
    "\n",
    "#net = Net()\n",
    "#net.load_state_dict(torch.load('/content/gdrive/My Drive/model_'+str(31)+'.pkl'))\n",
    "#use_cuda=True\n",
    "#\n",
    "#if use_cuda and torch.cuda.is_available():\n",
    "#    net.cuda()\n",
    "#    print('using cuda')\n",
    "#else:\n",
    "#  print('not using cuda')\n",
    "#\n",
    "\n",
    "print('Calculating performance on test set')\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=1,shuffle=False, num_workers=2)\n",
    "test_data=np.zeros((len(test),2))\n",
    "for i, data in enumerate(testloader, 0):\n",
    "# get the inputs\n",
    "  images, labels = data\n",
    "  images=Variable(images)\n",
    "  labels=Variable(labels[0])\n",
    "  \n",
    "  if use_cuda and torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "  \n",
    "  outputs = net(images)\n",
    "  #print(labels.cpu().numpy())\n",
    "  test_data[i,:]=[labels.cpu().numpy(),np.argmax(outputs.data.cpu().numpy())]\n",
    "test_data=test_data[np.argsort(test_data[:, 0])]\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUI6vAjlUfYD"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('/content/gdrive/My Drive/submission_file.csv','w') as csvFile:\n",
    "    writer = csv.writer(csvFile,lineterminator = '\\n')\n",
    "    writer.writerow(['id','label'])\n",
    "    for i in range(test_data.shape[0]):\n",
    "      if test_data[i,1]==0:\n",
    "        writer.writerow([test_data[i,0].astype(np.int32),'Cat'])\n",
    "      else:\n",
    "        writer.writerow([test_data[i,0].astype(np.int32),'Dog'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Ass1_P3",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
